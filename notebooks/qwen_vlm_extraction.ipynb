{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen2.5-VL-7B-Instruct for Structured Information Extraction\n",
    "\n",
    "This notebook demonstrates how to use Qwen2.5-VL-7B-Instruct model to extract structured information from images, particularly focused on invoice and document processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.11.13 environment at: /Users/huetuanthi/dev/dokeai/vlm-ocr/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "!uv pip install transformers torch torchvision pillow accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from PIL import Image\n",
    "import json\n",
    "from typing import Dict, Any, List, Optional\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QwenVLMExtractor:\n",
    "    def __init__(self, model_name: str = \"Qwen/Qwen2-VL-7B-Instruct\"):\n",
    "        \"\"\"Initialize the Qwen VLM model for information extraction.\"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Load model and processor\n",
    "        self.model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        self.processor = AutoProcessor.from_pretrained(model_name)\n",
    "        \n",
    "    def create_prompt(self, task_description: str = \"Extract all relevant information\", \n",
    "                     output_format: Optional[Dict] = None) -> str:\n",
    "        \"\"\"Create an optimized prompt for information extraction.\"\"\"\n",
    "        \n",
    "        system_prompt = \"\"\"You are an advanced Vision Language Model specialized in extracting structured information from images.\n",
    "Your capabilities include:\n",
    "- Accurate text recognition (OCR)\n",
    "- Understanding document layouts and structures\n",
    "- Extracting key-value pairs, tables, and hierarchical information\n",
    "- Identifying and categorizing different types of information\n",
    "\n",
    "Guidelines:\n",
    "1. Extract ALL visible text and information from the image\n",
    "2. Preserve the original structure and relationships between elements\n",
    "3. Output valid JSON format\n",
    "4. Include confidence indicators where appropriate\n",
    "5. Handle multiple languages if present\"\"\"\n",
    "        \n",
    "        if output_format:\n",
    "            format_instruction = f\"\\n\\nExpected output format:\\n{json.dumps(output_format, indent=2)}\"\n",
    "        else:\n",
    "            format_instruction = \"\"\n",
    "        \n",
    "        user_prompt = f\"{task_description}{format_instruction}\"\n",
    "        \n",
    "        # Construct the full prompt with proper tags\n",
    "        full_prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "<|vision_start|><|image_pad|><|vision_end|>{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "        \n",
    "        return full_prompt\n",
    "    \n",
    "    def extract_information(self, \n",
    "                          image_path: str, \n",
    "                          task_description: str = \"Extract all relevant information from this image\",\n",
    "                          output_format: Optional[Dict] = None,\n",
    "                          max_new_tokens: int = 1024) -> Dict[str, Any]:\n",
    "        \"\"\"Extract structured information from an image.\"\"\"\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = self.create_prompt(task_description, output_format)\n",
    "        \n",
    "        # Prepare inputs\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": image,\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": task_description},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Process with the model\n",
    "        text = self.processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = self.processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(self.device)\n",
    "        \n",
    "        # Generate response\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=0.1,  # Low temperature for more deterministic outputs\n",
    "                do_sample=True,\n",
    "            )\n",
    "        \n",
    "        # Decode the response\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        output_text = self.processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "        \n",
    "        # Parse JSON response\n",
    "        try:\n",
    "            result = json.loads(output_text)\n",
    "        except json.JSONDecodeError:\n",
    "            # If JSON parsing fails, return raw text\n",
    "            result = {\"raw_output\": output_text, \"parse_error\": \"Failed to parse JSON\"}\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vision_info(messages):\n",
    "    \"\"\"Process vision information from messages.\"\"\"\n",
    "    image_inputs = []\n",
    "    video_inputs = []\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            for content in message[\"content\"]:\n",
    "                if content[\"type\"] == \"image\":\n",
    "                    image_inputs.append(content[\"image\"])\n",
    "                elif content[\"type\"] == \"video\":\n",
    "                    video_inputs.append(content[\"video\"])\n",
    "    \n",
    "    return image_inputs, video_inputs\n",
    "\n",
    "def create_invoice_schema():\n",
    "    \"\"\"Create a sample schema for invoice extraction.\"\"\"\n",
    "    return {\n",
    "        \"invoice_details\": {\n",
    "            \"invoice_number\": \"string\",\n",
    "            \"invoice_date\": \"string\",\n",
    "            \"due_date\": \"string\",\n",
    "            \"currency\": \"string\",\n",
    "            \"total_amount\": \"number\"\n",
    "        },\n",
    "        \"vendor_details\": {\n",
    "            \"name\": \"string\",\n",
    "            \"address\": \"string\",\n",
    "            \"tax_id\": \"string\",\n",
    "            \"contact\": \"string\"\n",
    "        },\n",
    "        \"customer_details\": {\n",
    "            \"name\": \"string\",\n",
    "            \"address\": \"string\",\n",
    "            \"tax_id\": \"string\",\n",
    "            \"contact\": \"string\"\n",
    "        },\n",
    "        \"line_items\": [\n",
    "            {\n",
    "                \"description\": \"string\",\n",
    "                \"quantity\": \"number\",\n",
    "                \"unit_price\": \"number\",\n",
    "                \"total\": \"number\"\n",
    "            }\n",
    "        ],\n",
    "        \"tax_details\": {\n",
    "            \"tax_rate\": \"number\",\n",
    "            \"tax_amount\": \"number\"\n",
    "        },\n",
    "        \"payment_details\": {\n",
    "            \"method\": \"string\",\n",
    "            \"account_number\": \"string\",\n",
    "            \"reference\": \"string\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9788c8c4fbb04289ae81e50c15a1a7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743225c93bff41ff8968af18561b395b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a311eb69744558a7ae4f47b462826f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0ae1ed00004ea2a39e17a4200c4297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaad3805114a420580b48346ae7e67d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a16f68c55134c6e8b1f5cd36a41e62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11497df007ab4a13852fb43d977492b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the extractor\n",
    "extractor = QwenVLMExtractor()\n",
    "\n",
    "# Example: Extract information from an invoice\n",
    "# Note: Replace with your actual image path\n",
    "image_path = \"path/to/your/invoice.jpg\"\n",
    "\n",
    "# Define the extraction task\n",
    "task_description = \"\"\"Extract all information from this invoice image. \n",
    "Focus on:\n",
    "1. Invoice metadata (number, dates, amounts)\n",
    "2. Vendor and customer information\n",
    "3. Line items with descriptions and amounts\n",
    "4. Tax and payment details\n",
    "\n",
    "Return the information as structured JSON.\"\"\"\n",
    "\n",
    "# Get the schema for structured output\n",
    "invoice_schema = create_invoice_schema()\n",
    "\n",
    "# Extract information\n",
    "if os.path.exists(image_path):\n",
    "    result = extractor.extract_information(\n",
    "        image_path=image_path,\n",
    "        task_description=task_description,\n",
    "        output_format=invoice_schema\n",
    "    )\n",
    "    \n",
    "    print(\"Extracted Information:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "else:\n",
    "    print(f\"Please provide a valid image path. Current path '{image_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_extract(extractor: QwenVLMExtractor, \n",
    "                 image_folder: str, \n",
    "                 task_description: str,\n",
    "                 output_format: Optional[Dict] = None) -> List[Dict]:\n",
    "    \"\"\"Process multiple images in a folder.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "    \n",
    "    folder_path = Path(image_folder)\n",
    "    image_files = [f for f in folder_path.iterdir() \n",
    "                  if f.suffix.lower() in image_extensions]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images to process\")\n",
    "    \n",
    "    for idx, image_file in enumerate(image_files):\n",
    "        print(f\"\\nProcessing {idx+1}/{len(image_files)}: {image_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            result = extractor.extract_information(\n",
    "                image_path=str(image_file),\n",
    "                task_description=task_description,\n",
    "                output_format=output_format\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                \"filename\": image_file.name,\n",
    "                \"extracted_data\": result,\n",
    "                \"status\": \"success\"\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"filename\": image_file.name,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"failed\"\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example batch processing\n",
    "# image_folder = \"path/to/invoice/folder\"\n",
    "# batch_results = batch_extract(extractor, image_folder, task_description, invoice_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Extraction Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for receipt extraction\n",
    "receipt_template = {\n",
    "    \"store_info\": {\n",
    "        \"name\": \"string\",\n",
    "        \"address\": \"string\",\n",
    "        \"phone\": \"string\"\n",
    "    },\n",
    "    \"transaction_info\": {\n",
    "        \"date\": \"string\",\n",
    "        \"time\": \"string\",\n",
    "        \"receipt_number\": \"string\",\n",
    "        \"cashier\": \"string\"\n",
    "    },\n",
    "    \"items\": [\n",
    "        {\n",
    "            \"name\": \"string\",\n",
    "            \"quantity\": \"number\",\n",
    "            \"price\": \"number\"\n",
    "        }\n",
    "    ],\n",
    "    \"totals\": {\n",
    "        \"subtotal\": \"number\",\n",
    "        \"tax\": \"number\",\n",
    "        \"total\": \"number\"\n",
    "    },\n",
    "    \"payment\": {\n",
    "        \"method\": \"string\",\n",
    "        \"amount_paid\": \"number\",\n",
    "        \"change\": \"number\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Template for ID card extraction\n",
    "id_card_template = {\n",
    "    \"personal_info\": {\n",
    "        \"full_name\": \"string\",\n",
    "        \"date_of_birth\": \"string\",\n",
    "        \"gender\": \"string\",\n",
    "        \"nationality\": \"string\"\n",
    "    },\n",
    "    \"document_info\": {\n",
    "        \"document_type\": \"string\",\n",
    "        \"document_number\": \"string\",\n",
    "        \"issue_date\": \"string\",\n",
    "        \"expiry_date\": \"string\",\n",
    "        \"issuing_authority\": \"string\"\n",
    "    },\n",
    "    \"address\": {\n",
    "        \"street\": \"string\",\n",
    "        \"city\": \"string\",\n",
    "        \"state\": \"string\",\n",
    "        \"postal_code\": \"string\",\n",
    "        \"country\": \"string\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Template for business card extraction\n",
    "business_card_template = {\n",
    "    \"person\": {\n",
    "        \"name\": \"string\",\n",
    "        \"title\": \"string\",\n",
    "        \"department\": \"string\"\n",
    "    },\n",
    "    \"company\": {\n",
    "        \"name\": \"string\",\n",
    "        \"tagline\": \"string\",\n",
    "        \"industry\": \"string\"\n",
    "    },\n",
    "    \"contact\": {\n",
    "        \"phone\": [\"string\"],\n",
    "        \"email\": [\"string\"],\n",
    "        \"website\": \"string\",\n",
    "        \"address\": \"string\"\n",
    "    },\n",
    "    \"social_media\": {\n",
    "        \"linkedin\": \"string\",\n",
    "        \"twitter\": \"string\",\n",
    "        \"other\": [\"string\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_extraction_results(results: List[Dict], output_file: str):\n",
    "    \"\"\"Save extraction results to a JSON file.\"\"\"\n",
    "    \n",
    "    output_path = Path(output_file)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "# Example: Save results\n",
    "# save_extraction_results(batch_results, \"extraction_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
